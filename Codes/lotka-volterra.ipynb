{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8350a97e-1b66-4ec2-a81f-c3aebc7ab2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numpy import array, where, eye, linspace, matrix, hstack\n",
    "from scipy import integrate\n",
    "from scipy.stats import lognorm,gamma\n",
    "from numpy import array, where\n",
    "from numpy.random import seed, shuffle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb1c9e1-de4c-439a-8254-4b10fe7ca837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dX_dt_template(C):\n",
    "    return lambda X, t=0: X*array(matrix(C)*matrix(hstack((array([1]),X))).T).reshape(len(X))\n",
    "\n",
    "def lokta_volterra(dX_dt, X0, lb, ub, ts):\n",
    "    t = linspace(lb, ub,  ts) #timesteps to eval lv at\n",
    "    X = integrate.odeint(dX_dt, X0, t)\n",
    "    return X.T #transpose to make otusXsamples\n",
    "\n",
    "def model1_otu(df_and_params, samples):\n",
    "    \"\"\"Return an otu vector drawn from df given params and of length samples.\"\"\"\n",
    "    return df_and_params[0].rvs(*df_and_params[1:],size=samples)\n",
    "\n",
    "def model1_table(dfs_and_params, samples):\n",
    "    return np.array([model1_otu(i,samples) for i in dfs_and_params])\n",
    "\n",
    "def alter_table(data, as_abund=True, as_int=False, sparsity=.8):\n",
    "    \"\"\"Change table to RA, to int, and/or add sparsity.\"\"\"\n",
    "    res = data\n",
    "    if not as_abund:\n",
    "        res = res/res.sum(0)\n",
    "    if as_int:\n",
    "        res = res.round(0)\n",
    "    if sparsity:\n",
    "        r,c = where(data==data)\n",
    "        q = list(zip(r,c))\n",
    "        shuffle(q)\n",
    "        for i in range(int(len(q)*sparsity)):\n",
    "            res[q[i]] = 0.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed35c28-4f08-4eab-a856-e34c85bf6443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(30968340693)\n",
    "two_species_interaction_matrices = [\\\n",
    "array([[1., 0, -.1],\n",
    "[-1.5, 0.075, 0]]),\n",
    "array([[1., 0, -.1],\n",
    "[-0.5, 0.075, 0]]),\n",
    "array([[1, 0, -.1],\n",
    "[-10, 0.075, 0]]),\n",
    "array([[10, 0, -.1],\n",
    "[-10, 0.075, 0]]),\n",
    "array([[-1, 0, -.1],\n",
    "[-1.5, 0.075, 0]]),\n",
    "array([[-0.1, 0, -.1],\n",
    "[-1.5, 0.075, 0]]),\n",
    "array([[0, 0, -.1],\n",
    "[-1.5, 0.075, 0]]),\n",
    "array([[0, 0, -.1],\n",
    "[0, 0.075, 0]]),\n",
    "array([[1., 0, -1],\n",
    "[-1.5, 1, 0]]),\n",
    "array([[4, -2, -2],\n",
    "[1, 1, -2]])]\n",
    "\n",
    "six_species_interaction_matrices = [\\\n",
    "array([[2, 0, -2, 0, 0, 0, 0],\n",
    "[1, 2, -1, -2, 0, 0, 0],\n",
    "[4, 0, 2, 0, -2, -2, -2],\n",
    "[-1, 0, 0, 2, 0, -1, 0],\n",
    "[-3, 0, 0, 2, 1, 0, 0],\n",
    "[-1, 0, 0, 2, 0, 0, -1]]),\n",
    "array([[2,-10,-2,0,0,0,0],\n",
    "[1,10,-1,-2,0,0,0],\n",
    "[4,10,2,0,-2,-2,-2],\n",
    "[-1,-10,0,2,0,-1,0],\n",
    "[-3,-10,0,2,1,0,0],\n",
    "[-10,-10,0,2,0,0,-1]]),\n",
    "array([[10,-10,-2,0,0,0,0],\n",
    "[1,10,-1,-2,0,0,0],\n",
    "[4,10,2,0,-2,-2,-2],\n",
    "[-1,-10,0,2,0,-1,0],\n",
    "[-3,-10,0,2,1,0,0],\n",
    "[-1,-10,0,2,0,0,-1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9a7398-a75b-4a19-a55a-e59067387159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# two_species_otu_table\n",
    "two_species_otu_table = []\n",
    "for C in two_species_interaction_matrices:\n",
    "    f = dX_dt_template(C)\n",
    "    Y = lokta_volterra(f, array([10]*C.shape[0]), 0, 20, 10000)\n",
    "    two_species_otu_table.extend([Y[0],Y[1]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632964aa-6ced-4ad4-87a2-0951b1810d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# shape is 20 x 10000\n",
    "two_species_otu_table = np.vstack(two_species_otu_table)\n",
    "\n",
    "# make 5 tables:\n",
    "# 1. relative abundance table with pts taken at equal intervals\n",
    "# 2. counts table with pts taken at equal intervals (same pts as 1)\n",
    "# 3. relative abundance table with pts taken at random indices\n",
    "# 4. counts table with pts taken at random intervals (same pts as 3)\n",
    "# 5. table with 60 percent sparsity \n",
    "\n",
    "# must add 80 completely random OTUs to confound + pad the table\n",
    "\n",
    "# generate 40 otus from lognorm distribution 2,0,1 \n",
    "dfs_and_params = [[lognorm, 2, 0]]*40\n",
    "otus_lognorm_2_0 = model1_table(dfs_and_params, 50)\n",
    "# generate 40 otus from gamma distribution 1,0,10\n",
    "dfs_and_params = [[gamma, 1, 0, 10]]*40\n",
    "otus_gamma_1_0_10 = model1_table(dfs_and_params, 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee123fc5-fd4b-4448-bb46-0d2e049172dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "evenly_sampled_indices = np.arange(50)*200\n",
    "random_indices = np.arange(10000)\n",
    "random.shuffle(random_indices)\n",
    "random_indices = random_indices[:50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9eb934-28f7-4209-9a4f-adf73c7fb1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lv_table_2sp_12_base = np.vstack([two_species_otu_table[:,evenly_sampled_indices], \n",
    "    otus_gamma_1_0_10, otus_lognorm_2_0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c8dd4d-8d07-404f-9d83-e5763960594b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lv_table_2sp_1 = (lv_table_2sp_12_base/lv_table_2sp_12_base.sum(0))\n",
    "lv_table_2sp_2 = 100*lv_table_2sp_12_base.round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819c6544-b608-413d-94f2-eb6a6dcaaedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lv_table_2sp_34_base = np.vstack([two_species_otu_table[:,random_indices], \n",
    "    otus_gamma_1_0_10, otus_lognorm_2_0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55076c9-1575-4eef-91c1-993986256d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lv_table_2sp_3 = (lv_table_2sp_34_base/lv_table_2sp_34_base.sum(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "976f8bb8-63fc-4b42-8207-6b77657d6852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "lv_table_2sp_4 = 100*lv_table_2sp_34_base.round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3017693d-ac1d-4022-90de-5954bf36156b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lv_table_2sp_5 = alter_table(lv_table_2sp_12_base, sparsity=.6).round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93edf03e-ecdc-4530-9730-02af1948967a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# six_species_otu_tables\n",
    "six_species_otu_tables = []\n",
    "for C in six_species_interaction_matrices:\n",
    "    f = dX_dt_template(C)\n",
    "    Y = lokta_volterra(f, array([10]*C.shape[0]), 0, 20, 10000)\n",
    "    six_species_otu_tables.append(Y)\n",
    "\n",
    "six_species_otu_table = np.vstack(six_species_otu_tables)\n",
    "\n",
    "# make 5 tables:\n",
    "# 1. relative abundance table with pts taken at equal intervals\n",
    "# 2. counts table with pts taken at equal intervals (same pts as 1)\n",
    "# 3. relative abundance table with pts taken at random indices\n",
    "# 4. counts table with pts taken at random intervals (same pts as 3)\n",
    "# 5. table with 60 percent sparsity \n",
    "\n",
    "# must add 82 completely random OTUs to confound + pad the table\n",
    "\n",
    "# generate 42 otus from lognorm distribution 1,0,1 \n",
    "dfs_and_params = [[lognorm, 1, 0]]*42\n",
    "otus_lognorm_1_0 = model1_table(dfs_and_params, 50)\n",
    "# generate 42 otus from gamma distribution 1,0,10\n",
    "dfs_and_params = [[gamma, 1, 0, 10]]*42\n",
    "otus_gamma_1_0_10 = model1_table(dfs_and_params, 50)\n",
    "\n",
    "evenly_sampled_indices = np.arange(50)*200\n",
    "random_indices = np.arange(10000)\n",
    "random.shuffle(random_indices)\n",
    "random_indices = random_indices[:50]\n",
    "\n",
    "lv_table_6sp_12_base = np.vstack([six_species_otu_table[:,evenly_sampled_indices], \n",
    "    otus_gamma_1_0_10, otus_lognorm_1_0])\n",
    "lv_table_6sp_1 = (lv_table_6sp_12_base/lv_table_6sp_12_base.sum(0))\n",
    "lv_table_6sp_2 = 100*lv_table_6sp_12_base.round(0)\n",
    "lv_table_6sp_34_base = np.vstack([six_species_otu_table[:,random_indices], \n",
    "    otus_gamma_1_0_10, otus_lognorm_1_0])\n",
    "lv_table_6sp_3 = (lv_table_6sp_34_base/lv_table_6sp_34_base.sum(0))\n",
    "lv_table_6sp_4 = 100*lv_table_6sp_34_base.round(0)\n",
    "lv_table_6sp_5 = alter_table(lv_table_6sp_12_base, sparsity=.6).round(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# small negatives exist in two of the lv tables because of floating point \n",
    "# error, need to resolve this.\n",
    "lv_table_2sp_1_corr = where(lv_table_2sp_1>0, lv_table_2sp_1, 0)\n",
    "lv_table_2sp_3_corr = where(lv_table_2sp_3>0, lv_table_2sp_3, 0)\n",
    "\n",
    "all_tables = [lv_table_2sp_1_corr, lv_table_2sp_2, lv_table_2sp_3_corr, lv_table_2sp_4,\n",
    "    lv_table_2sp_5, lv_table_6sp_1, lv_table_6sp_2, lv_table_6sp_3,\n",
    "    lv_table_6sp_4, lv_table_6sp_5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4b354cf-5a8a-4523-8e99-5b91849deffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50)\n",
      "(100, 50)\n",
      "(100, 50)\n",
      "(100, 50)\n",
      "(100, 50)\n",
      "(102, 50)\n",
      "(102, 50)\n",
      "(102, 50)\n",
      "(102, 50)\n",
      "(102, 50)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(lv_table_2sp_1_corr))\n",
    "print(np.shape(lv_table_2sp_2))\n",
    "print(np.shape(lv_table_2sp_3_corr))\n",
    "print(np.shape(lv_table_2sp_4))\n",
    "print(np.shape(lv_table_2sp_5))\n",
    "print(np.shape(lv_table_6sp_1))\n",
    "print(np.shape(lv_table_6sp_2))\n",
    "print(np.shape(lv_table_6sp_3))\n",
    "print(np.shape(lv_table_6sp_4))\n",
    "print(np.shape(lv_table_6sp_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "793dd6e2-6c97-46cd-b4e2-d3bf8c8f75c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(lv_table_2sp_1_corr, index=['o'+str(i) for i in range(0, 100)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df2 = pd.DataFrame(lv_table_2sp_2, index=['o'+str(i) for i in range(0, 100)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df3 = pd.DataFrame(lv_table_2sp_3_corr, index=['o'+str(i) for i in range(0, 100)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df4 = pd.DataFrame(lv_table_2sp_4, index=['o'+str(i) for i in range(0, 100)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df5 = pd.DataFrame(lv_table_2sp_5, index=['o'+str(i) for i in range(0, 100)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df6 = pd.DataFrame(lv_table_6sp_1, index=['o'+str(i) for i in range(0, 102)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df7 = pd.DataFrame(lv_table_6sp_2, index=['o'+str(i) for i in range(0, 102)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df8 = pd.DataFrame(lv_table_6sp_3, index=['o'+str(i) for i in range(0, 102)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df9 = pd.DataFrame(lv_table_6sp_4, index=['o'+str(i) for i in range(0, 102)], columns=['s'+str(i) for i in range(0, 50)])\n",
    "df10 = pd.DataFrame(lv_table_6sp_5, index=['o'+str(i) for i in range(0, 102)], columns=['s'+str(i) for i in range(0, 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7213409e-44fa-4bfe-9ee9-31b58046258f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.to_csv('F:\\\\table\\\\Table Set 2.6.txt',sep='\\t')\n",
    "df2.to_csv('F:\\\\table\\\\Table Set 2.7.txt',sep='\\t')\n",
    "df3.to_csv('F:\\\\table\\\\Table Set 2.8.txt',sep='\\t')\n",
    "df4.to_csv('F:\\\\table\\\\Table Set 2.9.txt',sep='\\t')\n",
    "df5.to_csv('F:\\\\table\\\\Table Set 2.10.txt',sep='\\t')\n",
    "df6.to_csv('F:\\\\table\\\\Table Set 2.11.txt',sep='\\t')\n",
    "df7.to_csv('F:\\\\table\\\\Table Set 2.12.txt',sep='\\t')\n",
    "df8.to_csv('F:\\\\table\\\\Table Set 2.13.txt',sep='\\t')\n",
    "df9.to_csv('F:\\\\table\\\\Table Set 2.14.txt',sep='\\t')\n",
    "df10.to_csv('F:\\\\table\\\\Table Set 2.15.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2773b1-9eed-4c9f-9d6f-f8325231843d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
